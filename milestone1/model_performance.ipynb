{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./resnet-34_kinetics.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = \"./kinetics400/kinetics-downloader/dataset/test/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./kinetics400/test.csv\"\n",
    "labels = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6183/45598693.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  labels = labels.drop('time_start', 1)\n",
      "/tmp/ipykernel_6183/45598693.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  labels = labels.drop('time_end', 1)\n",
      "/tmp/ipykernel_6183/45598693.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  labels = labels.drop('split', 1)\n"
     ]
    }
   ],
   "source": [
    "labels = labels.drop('time_start', 1)\n",
    "labels = labels.drop('time_end', 1)\n",
    "labels = labels.drop('split', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--6bJUbfpnQ</th>\n",
       "      <td>drinking beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--8YXc8iCt8</th>\n",
       "      <td>climbing tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--coBvtS-eQ</th>\n",
       "      <td>surfing water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--q6ElFyVq0</th>\n",
       "      <td>stomping grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--q_mvQ8zP8</th>\n",
       "      <td>tai chi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzHsdlYe_5I</th>\n",
       "      <td>catching or throwing softball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzl-3zkieiE</th>\n",
       "      <td>skiing (not slalom or crosscountry)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzpqbqLllzA</th>\n",
       "      <td>jumping into pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzy_artj1B8</th>\n",
       "      <td>gargling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzkS3amkWE</th>\n",
       "      <td>juggling fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34885 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           label\n",
       "youtube_id                                      \n",
       "--6bJUbfpnQ                        drinking beer\n",
       "--8YXc8iCt8                        climbing tree\n",
       "--coBvtS-eQ                        surfing water\n",
       "--q6ElFyVq0                      stomping grapes\n",
       "--q_mvQ8zP8                              tai chi\n",
       "...                                          ...\n",
       "zzHsdlYe_5I        catching or throwing softball\n",
       "zzl-3zkieiE  skiing (not slalom or crosscountry)\n",
       "zzpqbqLllzA                    jumping into pool\n",
       "zzy_artj1B8                             gargling\n",
       "zzzkS3amkWE                        juggling fire\n",
       "\n",
       "[34885 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.set_index('youtube_id')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drinking beer\n"
     ]
    }
   ],
   "source": [
    "d = labels.to_dict('index')\n",
    "print(d['--6bJUbfpnQ']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DURATION = 16 \n",
    "SAMPLE_SIZE = 112 \n",
    "\n",
    "names = \"./action_recognition_kinetics.txt\"\n",
    "with open(names) as l:\n",
    "    CLASSES = l.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cartwheeling\n",
      "cartwheeling\n",
      "climbing tree\n",
      "climbing tree\n",
      "shredding paper\n",
      "shredding paper\n",
      "shoveling snow\n",
      "shoveling snow\n",
      "knitting\n",
      "knitting\n",
      "bartending\n",
      "bartending\n",
      "snorkeling\n",
      "snorkeling\n",
      "flipping pancake\n",
      "flipping pancake\n",
      "ironing\n",
      "ironing\n",
      "climbing a rope\n",
      "disc golfing\n",
      "playing piano\n",
      "playing piano\n",
      "playing guitar\n",
      "playing cello\n",
      "juggling fire\n",
      "spinning poi\n",
      "krumping\n",
      "breakdancing\n",
      "springboard diving\n",
      "springboard diving\n",
      "making a sandwich\n",
      "making pizza\n",
      "playing keyboard\n",
      "playing keyboard\n",
      "breakdancing\n",
      "dribbling basketball\n",
      "breakdancing\n",
      "punching person (boxing)\n",
      "country line dancing\n",
      "country line dancing\n",
      "tango dancing\n",
      "tango dancing\n",
      "riding camel\n",
      "riding camel\n",
      "gymnastics tumbling\n",
      "gymnastics tumbling\n",
      "scuba diving\n",
      "canoeing or kayaking\n",
      "unloading truck\n",
      "digging\n",
      "yoga\n",
      "cheerleading\n",
      "ice climbing\n",
      "ice climbing\n",
      "playing poker\n",
      "playing poker\n",
      "picking fruit\n",
      "picking fruit\n",
      "bookbinding\n",
      "bookbinding\n",
      "tap dancing\n",
      "country line dancing\n",
      "laughing\n",
      "laughing\n",
      "washing hair\n",
      "massaging back\n",
      "barbequing\n",
      "barbequing\n",
      "tying knot (not on a tie)\n",
      "knitting\n",
      "skiing slalom\n",
      "skiing (not slalom or crosscountry)\n",
      "bench pressing\n",
      "bench pressing\n",
      "kitesurfing\n",
      "kitesurfing\n",
      "skiing crosscountry\n",
      "skiing crosscountry\n",
      "pull ups\n",
      "pull ups\n",
      "strumming guitar\n",
      "strumming guitar\n",
      "stomping grapes\n",
      "stomping grapes\n",
      "drinking beer\n",
      "eating burger\n",
      "cutting nails\n",
      "getting a tattoo\n",
      "feeding fish\n",
      "feeding fish\n",
      "disc golfing\n",
      "disc golfing\n",
      "digging\n",
      "cleaning gutters\n",
      "baby waking up\n",
      "baby waking up\n",
      "swing dancing\n",
      "dancing charleston\n",
      "building cabinet\n",
      "bookbinding\n",
      "extinguishing fire\n",
      "extinguishing fire\n",
      "writing\n",
      "drawing\n",
      "cheerleading\n",
      "dancing ballet\n",
      "trapezing\n",
      "trapezing\n",
      "juggling balls\n",
      "juggling fire\n",
      "stomping grapes\n",
      "stomping grapes\n",
      "bending metal\n",
      "bending metal\n",
      "peeling apples\n",
      "peeling apples\n",
      "grinding meat\n",
      "grinding meat\n",
      "playing ukulele\n",
      "playing ukulele\n",
      "hockey stop\n",
      "ice skating\n",
      "baby waking up\n",
      "baby waking up\n",
      "spraying\n",
      "cleaning windows\n",
      "scuba diving\n",
      "scuba diving\n",
      "ironing\n",
      "using computer\n",
      "playing squash or racquetball\n",
      "playing squash or racquetball\n",
      "digging\n",
      "riding camel\n",
      "writing\n",
      "writing\n",
      "petting animal (not cat)\n",
      "feeding goats\n",
      "making pizza\n",
      "making pizza\n",
      "slacklining\n",
      "slacklining\n",
      "cooking on campfire\n",
      "barbequing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# otherwise, the frame was read so resize it and add it to\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# our frames list\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mimutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# now that our frames array is filled we can construct our blob\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/m1/lib/python3.8/site-packages/imutils/convenience.py:91\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     88\u001b[0m     dim \u001b[38;5;241m=\u001b[39m (width, \u001b[38;5;28mint\u001b[39m(h \u001b[38;5;241m*\u001b[39m r))\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# resize the image\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# return the resized image\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resized\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for video in onlyfiles:\n",
    "    v_path = os.path.join(mypath, video)\n",
    "    #print(v_path)\n",
    "    vs = cv2.VideoCapture(v_path)\n",
    "    # initialize the list / dictionaries to captured classified frames\n",
    "    classifiedFrames = []\n",
    "    framesDict = []\n",
    "    predictions = []\n",
    "    dictKey = {}\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    n = 0\n",
    "    \n",
    "    # Run the model\n",
    "    # loop until we explicitly break from it\n",
    "    while True:\n",
    "        # initialize the batch of frames that will be passed through the model\n",
    "        frames = []\n",
    "        n += 1\n",
    "        end_of_video=False\n",
    "    \n",
    "        # loop over the number of required sample frames\n",
    "        for i in range(16):\n",
    "            # read a frame from the video stream\n",
    "            (grabbed, frame) = vs.read()\n",
    "            #Identiy the frame number\n",
    "            pos_frame = vs.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    \n",
    "            # if the frame was not grabbed then we've reached the end of\n",
    "            # the video stream so exit the script\n",
    "            if not grabbed:\n",
    "                end_of_video=True\n",
    "                break\n",
    "            # otherwise, the frame was read so resize it and add it to\n",
    "            # our frames list\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "            frames.append(frame)\n",
    "  \n",
    "        # now that our frames array is filled we can construct our blob\n",
    "        if not end_of_video:\n",
    "            blob = cv2.dnn.blobFromImages(frames, 1.0, (SAMPLE_SIZE, SAMPLE_SIZE), (114.7748, 107.7354, 99.4750), \n",
    "                                swapRB=True, crop=True)\n",
    "            blob = np.transpose(blob, (1, 0, 2, 3))\n",
    "            blob = np.expand_dims(blob, axis=0)\n",
    "  \n",
    "            # pass the blob through the network to obtain our human activity\n",
    "            # recognition predictions\n",
    "            net.setInput(blob)\n",
    "            outputs = net.forward()\n",
    "            prediction = CLASSES[np.argmax(outputs)]\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        else:\n",
    "            major_pred, conf = Counter(predictions).most_common()[0]\n",
    "            break\n",
    "    answer = d[video.split(\".\")[0]]['label']\n",
    "    print(answer)\n",
    "    print(major_pred)\n",
    "    count += 1\n",
    "    if answer==major_pred:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Acc:\" + str(float(correct/count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
